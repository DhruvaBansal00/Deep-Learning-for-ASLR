{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU_with_Attention_BiDirectional.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvaBansal00/Deep-Learning-for-ASLR/blob/master/LSTMs/colabScripts/GRU_with_Attention_BiDirectional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5eNYJdhNMlG",
        "colab_type": "text"
      },
      "source": [
        "Basic Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw6d7m5MKJfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "61688a66-49fc-45a5-bb38-493fffbdd422"
      },
      "source": [
        "pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFbaOUiWKrTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2b6bbe67-1915-4318-f317-62e5c55b19f1"
      },
      "source": [
        "import torch\n",
        "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Deep-Learning-for-ASLR/LSTMs/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Deep-Learning-for-ASLR/LSTMs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zekYo16sP1Qr",
        "colab_type": "text"
      },
      "source": [
        "Language Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTDU_GvvPzf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {}\n",
        "        self.n_words = 0\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrsUvZv5Kjkd",
        "colab_type": "text"
      },
      "source": [
        "Encoder GRU setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfH2NvaTKfu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class EncoderGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.1, bidirectional=True):\n",
        "        super(EncoderGRU, self).__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRU(input_size, hidden_size, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output, hidden = self.gru(input, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self, batch=1):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        return torch.zeros(1 + self.bidirectional, batch, self.hidden_size, device=device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLbpsGXQyz-Y",
        "colab_type": "text"
      },
      "source": [
        "Decoder GRU with Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyZmdYdEy1w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderGRU(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout=0.1, max_input_length=470):\n",
        "        super(AttnDecoderGRU, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        # self.dropout_p = dropout_p\n",
        "        self.max_input_length = max_input_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_input_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
        "        # self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        # embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNmd0iM_LVcG",
        "colab_type": "text"
      },
      "source": [
        "Cross - Validation Fold generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3eoOWNAKgAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import torch\n",
        "from sklearn import model_selection\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence, device):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def split(pairs, lang, device):\n",
        "    train = []\n",
        "    test = []\n",
        "    for label in pairs:\n",
        "        label_tensor = tensorFromSentence(lang, label, device)\n",
        "        iters = pairs[label]\n",
        "        test_index = random.randint(0, len(iters) - 1)\n",
        "        accept_prob = random.random()\n",
        "        for i in range(len(iters)):\n",
        "            if i == test_index and len(iters) != 1 and accept_prob > 0.5:\n",
        "                test.append([iters[i], label_tensor])\n",
        "            else:\n",
        "                train.append([iters[i], label_tensor])\n",
        "    return train, test\n",
        "\n",
        "def kfoldSplit(pairs, lang, device, split=10):\n",
        "    folds = []\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    for label in pairs:\n",
        "        for iter in pairs[label]:\n",
        "            inputs.append(iter)\n",
        "            outputs.append(label)\n",
        "    \n",
        "    skf = model_selection.StratifiedKFold(n_splits=split, shuffle=True)\n",
        "    indices = skf.split(inputs, outputs)\n",
        "\n",
        "    for train_indices, test_indices in indices:\n",
        "        curr_train = []\n",
        "        curr_test = []\n",
        "        for indices in train_indices:\n",
        "            curr_train.append([inputs[indices], tensorFromSentence(lang,  outputs[indices], device)])\n",
        "        for indices in test_indices:\n",
        "            curr_test.append([inputs[indices], tensorFromSentence(lang,  outputs[indices], device)])\n",
        "        folds.append([curr_train, curr_test])\n",
        "    \n",
        "    return folds\n",
        "        \n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMiOxmB3LvSl",
        "colab_type": "text"
      },
      "source": [
        "Accuracy calculator and result documentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FakNorerKgKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, output_lang, sil0, sil1, max_input_length=470, max_output_length=5):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = sentence\n",
        "        input_length = len(sentence)\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_input_length, encoder.hidden_size * 2, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] = encoder_output\n",
        "\n",
        "        decoder_input = torch.tensor([[sil0]], device=device)\n",
        "        decoder_attentions = torch.zeros(max_output_length, max_input_length)\n",
        "\n",
        "        layers, batches, hidden_num = encoder_hidden.size()\n",
        "        decoder_hidden = encoder_hidden.view(1,2,1,hidden_num)[0][1].view(1,1,hidden_num)\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_output_length):\n",
        "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            decoder_attentions[di] = decoder_attn.data\n",
        "            if topi.item() == sil1:\n",
        "                decoded_words.append('sil1')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di+1]\n",
        "\n",
        "def calculateTrainingAccuracy(encoder, decoder, pairs, output_lang, sil0, sil1, file_name=None, write = True, max_input_length=470, max_output_length=5):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    results = None\n",
        "    if write:\n",
        "        results = open(file_name, 'w')\n",
        "    attention = None\n",
        "    for pair in pairs:\n",
        "        output_words, attention = evaluate(encoder, decoder, pair[0], output_lang, sil0, sil1, max_input_length=max_input_length, max_output_length=max_output_length)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        sent = [output_lang.index2word[i.item()] for i in pair[1]]\n",
        "        true_sentence = ' '.join(sent)\n",
        "        if write:\n",
        "            print('Predicted Sentence: ', output_sentence)\n",
        "            print('True Sentence: ' , true_sentence)\n",
        "            plt.matshow(attention.numpy())\n",
        "            print('Predicted Sentence: ', output_sentence, file=results)\n",
        "            print('True Sentence: ' , true_sentence, file=results)\n",
        "        answer = None\n",
        "        if output_sentence == true_sentence:\n",
        "            correct += 1\n",
        "            answer = \"CORRECT\"\n",
        "        else:\n",
        "            answer = \"INCORRECT\"\n",
        "        total += 1\n",
        "        if write:\n",
        "            print('Result: ', answer, file=results)\n",
        "    if write:\n",
        "        print('Recognition Total: ', str(correct/total), file=results)\n",
        "        results.close()\n",
        "    return correct/total\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO-yavYcLefW",
        "colab_type": "text"
      },
      "source": [
        "LSTM training methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-wTkIecKgNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random \n",
        "import time\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, sil0, sil1, max_input_length = 470):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = len(input_tensor)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_input_length, encoder.hidden_size*2, device=device)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output\n",
        "\n",
        "    decoder_input = torch.tensor([[sil0]], device=device)\n",
        "\n",
        "    layers, batches, hidden_num = encoder_hidden.size()\n",
        "    decoder_hidden = encoder_hidden.view(1,2,1,hidden_num)[0][1].view(1,1,hidden_num)\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, _ = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, _ = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == sil1:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "def testSetLoss(encoder, decoder, input_tensor, target_tensor, criterion, sil0, sil1, max_input_length=470):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = input_tensor\n",
        "        input_length = len(input_tensor)\n",
        "        target_length = target_tensor.size(0)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_outputs = torch.zeros(max_input_length, encoder.hidden_size * 2, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] = encoder_output\n",
        "\n",
        "        decoder_input = torch.tensor([[sil0]], device=device)\n",
        "\n",
        "        layers, batches, hidden_num = encoder_hidden.size()\n",
        "        decoder_hidden = encoder_hidden.view(1,2,1,hidden_num)[0][1].view(1,1,hidden_num)\n",
        "        \n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if topi.item() == sil1:\n",
        "                break\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return loss.item() / target_length\n",
        "\n",
        "def trainIters(encoder, decoder, epochs, train_set, test_set, sil0, sil1, output_lang, lr=1e-4, lr_decay=1, lr_drop_epoch=10, l2_penalty = 0, max_input_length=470, max_output_length = 6):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    test_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr, weight_decay = l2_penalty)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr, weight_decay = l2_penalty)\n",
        "\n",
        "    best_test_acc = -1\n",
        "    best_encoder = None\n",
        "    best_decoder = None\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, epochs + 1):\n",
        "        if iter == lr_drop_epoch:\n",
        "            encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr * (lr_decay)**(iter), weight_decay = l2_penalty)\n",
        "            decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr * (lr_decay)**(iter), weight_decay = l2_penalty)\n",
        "\n",
        "        for pairs in train_set:\n",
        "            input_tensor = pairs[0]\n",
        "            target_tensor = pairs[1]\n",
        "            loss = train(input_tensor, target_tensor, encoder,\n",
        "                        decoder, encoder_optimizer, decoder_optimizer, criterion, sil0, sil1, max_input_length=max_input_length)\n",
        "            print_loss_total += loss\n",
        "\n",
        "        for pair in test_set:\n",
        "            input_tensor = pair[0]\n",
        "            target_tensor = pair[1]\n",
        "            test_loss_total += testSetLoss(encoder, decoder, input_tensor, target_tensor, criterion, sil0, sil1, max_input_length=max_input_length)\n",
        "\n",
        "        print_loss_avg = print_loss_total / len(train_set)\n",
        "        test_loss_avg = test_loss_total / len(test_set)\n",
        "        print_loss_total = 0\n",
        "        test_loss_total = 0\n",
        "        test_acc = calculateTrainingAccuracy(encoder, decoder, test_set, output_lang, sil0, sil1, write=False, max_input_length=max_input_length, max_output_length=max_output_length)\n",
        "        train_acc = calculateTrainingAccuracy(encoder, decoder, train_set, output_lang, sil0, sil1, write=False, max_input_length=max_input_length, max_output_length=max_output_length)\n",
        "        print('%s (%d %d%%) train loss: %.4f train acc: %.4f test loss: %.4f test acc: %.4f' % (timeSince(start, iter / epochs),\n",
        "                                        iter, iter / epochs * 100, print_loss_avg, train_acc, test_loss_avg, test_acc))\n",
        "        \n",
        "        if test_acc > best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "            best_encoder = copy.deepcopy(encoder)\n",
        "            best_decoder = copy.deepcopy(decoder)\n",
        "\n",
        "        plot_losses.append(test_loss_avg)\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "    return best_encoder, best_decoder"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owWXYW6vMFN6",
        "colab_type": "text"
      },
      "source": [
        "Main script - uses above files to run everything"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8888m0AKgH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fccba91-1a80-401d-9374-9e0d9965897a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import random\n",
        "import math\n",
        "\n",
        "#########    HYPERPARAMETERS   ############\n",
        "random.seed(24)\n",
        "users = [\"Matthew\"]\n",
        "file_name = \"Matthew\"\n",
        "num_features = 0\n",
        "hidden_size = 64\n",
        "epochs = 100\n",
        "limit_features = False\n",
        "lr = 1e-4\n",
        "lr_decay = 0.95\n",
        "lr_drop = 20\n",
        "dropout = 0\n",
        "num_layers = 1\n",
        "k_fold = False\n",
        "folds = 5\n",
        "bidirectional = True\n",
        "expansion_factor = 2\n",
        "l2_penalty = 0\n",
        "###########################################\n",
        "\n",
        "sil0 = 0\n",
        "sil1 = 0\n",
        "\n",
        "def expand(dataset_as_array, factor):\n",
        "    expanded_array = []\n",
        "    for pair in dataset_as_array:\n",
        "        content = pair[0]\n",
        "        label = pair[1]\n",
        "\n",
        "        expanded_pair = [[[],label] for i in range(factor)]\n",
        "        for frame in range(len(content)):\n",
        "            expanded_pair[frame % factor][0].append(content[frame])\n",
        "        expanded_array.extend(expanded_pair)\n",
        "    return expanded_array\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "eng = Lang(\"english\")\n",
        "pairs = {}\n",
        "max_input_length = 0\n",
        "max_output_length = 0\n",
        "print(\"Reading data from files...\")\n",
        "for user in users:\n",
        "    print(glob.glob(\"../data/ark/*\"+user+\"*.ark\"))\n",
        "    for file in glob.glob(\"../data/ark/*\"+user+\"*.ark\"):\n",
        "        label = \"sil0_\"+file.split(\"/\")[-1].split(\".\")[1]+\"_sil1\"\n",
        "        label = label.replace(\"_\", \" \")\n",
        "        eng.addSentence(label)\n",
        "\n",
        "        max_output_length = max(max_output_length - 1, len(label.split(\" \")))\n",
        "\n",
        "        sil0 = eng.word2index[\"sil0\"]\n",
        "        sil1 = eng.word2index[\"sil1\"]\n",
        "        content = []\n",
        "        f = open(file)\n",
        "        for x in f:\n",
        "            line = x\n",
        "            if \"[\" in x:\n",
        "                line = x.split(\"[ \")[1]\n",
        "            elif \"]\" in x:\n",
        "                line = x.split(\"]\")[0]\n",
        "            features = []\n",
        "            line = line.strip(\"\\n\").split(\" \")\n",
        "            for f in line:\n",
        "                try:\n",
        "                    features.append(float(f))\n",
        "                except:\n",
        "                    pass\n",
        "            if len(features) != 0:\n",
        "                num_features = len(features)\n",
        "                content.append(torch.tensor(features, dtype=torch.float, device=device).view(1, 1, -1))\n",
        "        max_input_length = max(max_input_length, len(content))\n",
        "        if label in pairs:\n",
        "            temp = pairs[label]\n",
        "            temp.append(content)\n",
        "            pairs[label] = temp\n",
        "        else:\n",
        "            pairs[label] = [content]\n",
        "\n",
        "print(\"Max Input length = \"+str(max_input_length) + \" Max output length = \" + str(max_output_length))\n",
        "\n",
        "for label in pairs:\n",
        "    print(\"Label = \" + label + \" Number of iterations = \" + str(len(pairs[label])))\n",
        "if not k_fold:    \n",
        "    print(\"Splitting data into train and test...\")\n",
        "    train_set, test_set = split(pairs, eng, device)\n",
        "    encoder = EncoderGRU(num_features, hidden_size, dropout=dropout, bidirectional=bidirectional).to(device)\n",
        "    decoder = AttnDecoderGRU(hidden_size, eng.n_words, dropout=dropout, max_input_length=max_input_length).to(device)\n",
        "    print(\"Split done. Elements in train: %d and elements in test: %d. Starting training...\" % (len(train_set), len(test_set)))\n",
        "    best_encoder, best_decoder = trainIters(encoder, decoder, epochs, train_set, test_set, sil0, sil1, eng, lr=lr, lr_decay=lr_decay, lr_drop_epoch=lr_drop, l2_penalty=l2_penalty, max_input_length=max_input_length, max_output_length=max_output_length)\n",
        "    print(\"Training done. Printing stats to file....\")\n",
        "    calculateTrainingAccuracy(best_encoder, best_decoder, test_set, eng, sil0, sil1, 'results/'+file_name+'/results.txt')\n",
        "    # print(\"Saving Models\")\n",
        "    # torch.save(best_encoder.state_dict(), \"models/\"+file_name+\"/encoderLSTM.pt\")\n",
        "    # torch.save(best_decoder.state_dict(), \"models/\"+file_name+\"/decoderLSTM.pt\")\n",
        "\n",
        "else:\n",
        "    print(\"Generating folds...\")\n",
        "    trainTestFolds = kfoldSplit(pairs, eng, device, split=folds)\n",
        "    print(\"Fold generation done...\")\n",
        "    fold_num = 1\n",
        "    for curr_fold in trainTestFolds:\n",
        "        encoder = EncoderGRU(num_features, hidden_size, dropout, bidirectional=bidirectional).to(device)\n",
        "        decoder = AttnDecoderGRU(hidden_size, eng.n_words, bidirectional=bidirectional, max_input_length=max_input_length).to(device)\n",
        "        print(\"Starting training on fold %d. %d elements in curr_fold[0] and %d in curr_fold[1]\" % (fold_num, len(curr_fold[0]), len(curr_fold[1])))\n",
        "        best_encoder, best_decoder = trainIters(encoder, decoder, epochs, curr_fold[0], curr_fold[1], sil0, sil1, eng, lr=lr, lr_decay=lr_decay, lr_drop_epoch=lr_drop, l2_penalty=l2_penalty, max_input_length=max_input_length, max_output_length=max_output_length)\n",
        "        print(\"Training done. Saving predictions to file...\")\n",
        "        calculateTrainingAccuracy(best_encoder, best_decoder, curr_fold[1], eng, sil0, sil1, 'results/'+file_name+'/results_fold'+str(fold_num)+'.txt')\n",
        "        # print(\"Saving Models\")\n",
        "        # torch.save(best_encoder.state_dict(), \"models/\"+file_name+\"/encoderLSTM_fold\"+str(fold_num)+\".pt\")\n",
        "        # torch.save(best_decoder.state_dict(), \"models/\"+file_name+\"/decoderLSTM_fold\"+str(fold_num)+\".pt\")\n",
        "        fold_num += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading data from files...\n",
            "['../data/ark/07-24-20_Matthew_4K.alligator_in_wagon.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wagon.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.blue_alligator_above_grey_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_orange_bed.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_bed.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_box.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_blue_box.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.blue_alligator_above_grey_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.grey_monkey_below_orange_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_wagon.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.black_monkey_in_white_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_black_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_blue_bed.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_bed.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.blue_monkey_above_grey_box.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_orange_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_bed.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.blue_alligator_above_grey_wall.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_orange_wagon.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_orange_bed.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_bed.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_orange_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_white_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_blue_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_orange_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_orange_bed.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_blue_box.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.blue_alligator_above_grey_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.black_monkey_in_white_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_wagon.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.black_monkey_in_white_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_blue_bed.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_blue_bed.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.grey_monkey_below_orange_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_orange_wagon.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_orange_wagon.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_blue_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_blue_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_orange_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_above_grey_bed.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_black_wall.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_wagon.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_bed.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_bed.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_wagon.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_box.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_bed.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_box.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_wall.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wagon.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_above_grey_bed.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_box.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_blue_bed.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_grey_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_box.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_blue_box.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_black_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_in_blue_wagon.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_white_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_orange_bed.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_white_wall.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_orange_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.grey_snake_below_blue_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_orange_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.black_monkey_in_white_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.grey_snake_below_blue_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.grey_monkey_below_orange_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_grey_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_blue_bed.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_blue_bed.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wagon.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_blue_box.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.black_snake_below_blue_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.black_snake_below_blue_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_bed.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_bed.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.blue_monkey_above_grey_box.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_box.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.black_monkey_in_white_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.grey_alligator_below_blue_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_below_grey_bed.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.grey_monkey_below_orange_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_orange_wagon.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_box.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.black_snake_below_blue_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_below_grey_bed.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_blue_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_below_grey_bed.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_black_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wall.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.black_alligator_above_orange_wagon.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.black_alligator_above_orange_wagon.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_wagon.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.blue_monkey_above_grey_box.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_bed.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_grey_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_wagon.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_orange_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.black_alligator_above_orange_wagon.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.grey_alligator_below_blue_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.grey_alligator_below_blue_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_box.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_blue_box.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_orange_wagon.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.grey_monkey_below_orange_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_orange_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_black_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_wagon.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.grey_snake_below_blue_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.blue_monkey_above_grey_box.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_bed.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.grey_snake_below_blue_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_bed.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_box.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.grey_snake_below_blue_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_in_blue_wagon.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_below_grey_bed.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_grey_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_blue_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_blue_bed.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_above_grey_bed.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_bed.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_orange_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_in_blue_wagon.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_bed.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_box.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_below_grey_bed.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_orange_bed.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_white_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_blue_bed.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_in_blue_wagon.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_above_grey_bed.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_above_white_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.grey_alligator_below_blue_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.lion_below_blue_bed.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_grey_wall.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.black_alligator_above_orange_wagon.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wagon.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.grey_alligator_below_blue_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_wagon.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_wagon.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.alligator_in_orange_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.lion_above_blue_bed.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.black_snake_below_blue_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_wall.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.blue_alligator_above_grey_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.black_snake_below_blue_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_in_blue_wagon.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.black_lion_above_grey_bed.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.alligator_above_blue_wagon.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.monkey_below_bed.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.blue_monkey_above_grey_box.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.black_alligator_above_orange_wagon.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_in_grey_box.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_wall.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.white_snake_in_blue_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_below_grey_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_box.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_orange_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_bed.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_black_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_orange_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_below_grey_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_below_grey_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_black_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_grey_wagon.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_orange_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_grey_box.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_grey_wagon.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_grey_box.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_below_grey_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_in_grey_box.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_chair.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.orange_alligator_in_grey_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_above_orange_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.white_snake_in_blue_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.white_alligator_above_blue_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_orange_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_in_grey_box.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_above_orange_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_box.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.white_snake_in_blue_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_bed.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.orange_alligator_in_grey_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_grey_wagon.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.white_alligator_above_blue_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_box.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_bed.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.orange_snake_below_blue_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_in_grey_box.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_grey_box.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.white_snake_in_blue_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_box.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_box.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_box.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.orange_snake_below_blue_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_box.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_above_orange_wall.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_wall.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_in_grey_box.0000000005.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_box.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_above_orange_wall.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_flowers.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_below_grey_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_grey_box.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_in_grey_box.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_grey_wagon.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_in_grey_box.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_above_orange_wall.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_flowers.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_bed.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_grey_box.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_box.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_in_grey_box.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.monkey_in_orange_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.snake_above_box.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_black_chair.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_chair.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.white_lion_in_grey_box.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.orange_snake_below_blue_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_bed.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.orange_alligator_in_grey_flowers.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_blue_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.orange_alligator_in_grey_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_in_grey_box.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.orange_snake_below_blue_flowers.0000000002.ark', '../data/ark/07-24-20_Matthew_4K.orange_alligator_in_grey_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.white_alligator_above_blue_wall.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.orange_monkey_in_grey_box.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_in_grey_wagon.0000000000.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_black_chair.0000000004.ark', '../data/ark/07-24-20_Matthew_4K.snake_below_black_chair.0000000003.ark', '../data/ark/07-24-20_Matthew_4K.white_snake_in_blue_flowers.0000000001.ark', '../data/ark/07-24-20_Matthew_4K.orange_snake_below_blue_flowers.0000000004.ark']\n",
            "Max Input length = 349 Max output length = 7\n",
            "Label = sil0 alligator in wagon sil1 Number of iterations = 5\n",
            "Label = sil0 alligator above blue wagon sil1 Number of iterations = 5\n",
            "Label = sil0 blue alligator above grey wall sil1 Number of iterations = 5\n",
            "Label = sil0 lion above orange bed sil1 Number of iterations = 5\n",
            "Label = sil0 alligator above bed sil1 Number of iterations = 5\n",
            "Label = sil0 alligator in box sil1 Number of iterations = 5\n",
            "Label = sil0 monkey in blue box sil1 Number of iterations = 5\n",
            "Label = sil0 grey monkey below orange chair sil1 Number of iterations = 5\n",
            "Label = sil0 monkey below wagon sil1 Number of iterations = 5\n",
            "Label = sil0 black monkey in white flowers sil1 Number of iterations = 5\n",
            "Label = sil0 alligator above black wall sil1 Number of iterations = 5\n",
            "Label = sil0 lion below blue bed sil1 Number of iterations = 5\n",
            "Label = sil0 monkey below bed sil1 Number of iterations = 5\n",
            "Label = sil0 lion above flowers sil1 Number of iterations = 5\n",
            "Label = sil0 blue monkey above grey box sil1 Number of iterations = 5\n",
            "Label = sil0 lion below orange chair sil1 Number of iterations = 5\n",
            "Label = sil0 alligator above orange wagon sil1 Number of iterations = 5\n",
            "Label = sil0 lion below chair sil1 Number of iterations = 5\n",
            "Label = sil0 monkey above chair sil1 Number of iterations = 5\n",
            "Label = sil0 monkey above white wall sil1 Number of iterations = 5\n",
            "Label = sil0 monkey below blue chair sil1 Number of iterations = 5\n",
            "Label = sil0 alligator in orange flowers sil1 Number of iterations = 5\n",
            "Label = sil0 monkey above wall sil1 Number of iterations = 5\n",
            "Label = sil0 alligator above wall sil1 Number of iterations = 5\n",
            "Label = sil0 lion above blue bed sil1 Number of iterations = 5\n",
            "Label = sil0 black lion above grey bed sil1 Number of iterations = 5\n",
            "Label = sil0 lion above bed sil1 Number of iterations = 5\n",
            "Label = sil0 alligator above chair sil1 Number of iterations = 5\n",
            "Label = sil0 lion above box sil1 Number of iterations = 5\n",
            "Label = sil0 lion above grey wall sil1 Number of iterations = 5\n",
            "Label = sil0 lion above wall sil1 Number of iterations = 4\n",
            "Label = sil0 black lion in blue wagon sil1 Number of iterations = 5\n",
            "Label = sil0 grey snake below blue chair sil1 Number of iterations = 5\n",
            "Label = sil0 alligator above blue wall sil1 Number of iterations = 5\n",
            "Label = sil0 black snake below blue chair sil1 Number of iterations = 5\n",
            "Label = sil0 grey alligator below blue flowers sil1 Number of iterations = 5\n",
            "Label = sil0 alligator below grey bed sil1 Number of iterations = 5\n",
            "Label = sil0 black alligator above orange wagon sil1 Number of iterations = 5\n",
            "Label = sil0 snake below blue flowers sil1 Number of iterations = 5\n",
            "Label = sil0 white lion in grey box sil1 Number of iterations = 5\n",
            "Label = sil0 snake above wall sil1 Number of iterations = 5\n",
            "Label = sil0 snake below chair sil1 Number of iterations = 5\n",
            "Label = sil0 white snake in blue flowers sil1 Number of iterations = 5\n",
            "Label = sil0 orange monkey below grey flowers sil1 Number of iterations = 5\n",
            "Label = sil0 monkey in box sil1 Number of iterations = 5\n",
            "Label = sil0 monkey in orange flowers sil1 Number of iterations = 5\n",
            "Label = sil0 snake below bed sil1 Number of iterations = 5\n",
            "Label = sil0 snake below black chair sil1 Number of iterations = 5\n",
            "Label = sil0 snake in grey wagon sil1 Number of iterations = 5\n",
            "Label = sil0 monkey in grey box sil1 Number of iterations = 5\n",
            "Label = sil0 snake below blue chair sil1 Number of iterations = 5\n",
            "Label = sil0 snake in flowers sil1 Number of iterations = 5\n",
            "Label = sil0 orange monkey in grey box sil1 Number of iterations = 6\n",
            "Label = sil0 orange alligator in grey flowers sil1 Number of iterations = 5\n",
            "Label = sil0 white lion above orange wall sil1 Number of iterations = 5\n",
            "Label = sil0 white alligator above blue wall sil1 Number of iterations = 3\n",
            "Label = sil0 orange snake below blue flowers sil1 Number of iterations = 5\n",
            "Label = sil0 snake above box sil1 Number of iterations = 5\n",
            "Splitting data into train and test...\n",
            "Split done. Elements in train: 253 and elements in test: 35. Starting training...\n",
            "1m 3s (- 104m 25s) (1 1%) train loss: 2.4738 train acc: 0.0000 test loss: 1.7965 test acc: 0.0000\n",
            "2m 6s (- 103m 9s) (2 2%) train loss: 1.9574 train acc: 0.0000 test loss: 1.5030 test acc: 0.0000\n",
            "3m 9s (- 102m 5s) (3 3%) train loss: 1.7814 train acc: 0.0000 test loss: 1.7310 test acc: 0.0000\n",
            "4m 12s (- 101m 8s) (4 4%) train loss: 1.6886 train acc: 0.0000 test loss: 1.6713 test acc: 0.0000\n",
            "5m 16s (- 100m 15s) (5 5%) train loss: 1.6465 train acc: 0.0000 test loss: 1.6100 test acc: 0.0000\n",
            "6m 19s (- 99m 11s) (6 6%) train loss: 1.5806 train acc: 0.0000 test loss: 1.5794 test acc: 0.0000\n",
            "7m 23s (- 98m 10s) (7 7%) train loss: 1.5289 train acc: 0.0000 test loss: 1.5507 test acc: 0.0000\n",
            "8m 26s (- 97m 6s) (8 8%) train loss: 1.4874 train acc: 0.0000 test loss: 1.5429 test acc: 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}